{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea12218-b235-4ae9-95eb-3195a2aa5bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH (n) RETURN COUNT(n)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(n)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(n)\n",
       "0     94193"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import openai\n",
    "#import aws secrets manager infrastructure\n",
    "import boto3 \n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neo4j\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import urllib.parse\n",
    "import os,sys\n",
    "\n",
    "def get_aws_secret_pws(pw_to_find):\n",
    "\n",
    "    secret_name = \"omealerts_pws/{}\".format(pw_to_find)\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    # In this sample we only handle the specific exceptions for the 'GetSecretValue' API.\n",
    "    # See https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "    # We rethrow the exception by default.\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "        return get_secret_value_response\n",
    "    except ClientError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "currentdir = os.path.dirname(os.path.realpath('Jupyterlab/Ankur_Notebooks/Sumi_KG/Neo4j_DS.ipynb'))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.append(parentdir)\n",
    "sys.path.append(currentdir)\n",
    "\n",
    "omealerts_kg_access_username = 'omealerts_kg_access'\n",
    "omealerts_kg_access_pw = json.loads(get_aws_secret_pws('omealerts_kg_access').get('SecretString', False)).get('omealerts_kg_access', None)\n",
    "\n",
    "host = \"bolt://10.115.1.170:7687\"\n",
    "user = omealerts_kg_access_username\n",
    "password = str(omealerts_kg_access_pw)\n",
    "database='ome-alerts'\n",
    "driver = GraphDatabase.driver(host,auth=(user, password))\n",
    "db =driver.session(database=database)\n",
    "\n",
    "openai.api_key = json.loads(get_aws_secret_pws('openai_api_key').get('SecretString'))['omealerts_pws/openai_api_key']\n",
    "MODEL=\"gpt-4\"\n",
    "\n",
    "def unpack_res(r):\n",
    "    res =  r['choices'][0]['message']['content']\n",
    "    tokens = r['usage']['total_tokens']\n",
    "    response = r\n",
    "    return res,tokens,response\n",
    "\n",
    "def run_query_df(query, params={}):\n",
    "    with driver.session(database=database) as session:\n",
    "        result = session.run(query, params)\n",
    "        data = [record.data() for record in result]\n",
    "        df = pd.json_normalize(data)\n",
    "        return df\n",
    "\n",
    "\n",
    "##Read cypher query results into Dataframe\n",
    "def run_query(query):\n",
    "        with driver.session(database=database) as session:\n",
    "            result = session.run(query)\n",
    "            print(query)\n",
    "            return pd.DataFrame([r.values() for r in result], columns=result.keys())\n",
    "\n",
    "\n",
    "# foo = run_query_df(\"\"\"MATCH (n) RETURN (n) LIMIT 5\"\"\")\n",
    "from neo4j import GraphDatabase\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as mcm\n",
    "from neo4j import GraphDatabase\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "run_query(\"MATCH (n) RETURN COUNT(n)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f0a76-f080-4d8c-a66c-4dc83d17dd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 49\n",
      "User_section 693\n",
      "Author_keywords 0\n",
      "Document_type 15\n",
      "Company_txt_ss 1824\n",
      "Indication_MeSH_txt_ss 2465\n",
      "drug_OME_txt_ss 4929\n",
      "target_OME_txt_ss 7073\n",
      "Keyword 1054\n",
      "Alias 43330\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# foo = run_query_df(\"\"\"MATCH (n) RETURN (n) LIMIT 5\"\"\")\n",
    "from neo4j import GraphDatabase\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as mcm\n",
    "from neo4j import GraphDatabase\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "class Neo4jHeteroGraphStore:\n",
    "    def __init__(self, uri, user, password, database, data_dir='data', use_file_storage=True):\n",
    "        self.graph = Graph(uri, name=database, auth=(user, password))\n",
    "        self.data_dir = data_dir\n",
    "        self.use_file_storage = use_file_storage\n",
    "        if not os.path.exists(self.data_dir):\n",
    "            os.makedirs(self.data_dir)\n",
    "    \n",
    "    def _save_data(self, data, filename):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(self.data_dir, filename), 'w') as f:\n",
    "                json.dump(data, f)\n",
    "    \n",
    "    def _load_data(self, filename):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(self.data_dir, filename)) as f:\n",
    "                return json.load(f)\n",
    "        return None\n",
    "    \n",
    "    def _data_exists(self, filename):\n",
    "        return os.path.exists(os.path.join(self.data_dir, filename))\n",
    "    \n",
    "    def fetch_nodes(self):\n",
    "        node_data = {}\n",
    "        node_types = self.graph.run(\"CALL db.labels()\").data()\n",
    "        for node_type in node_types:\n",
    "            label = node_type[\"label\"]\n",
    "            filename = f'nodes_{label}.json'\n",
    "            if self.use_file_storage and self._data_exists(filename):\n",
    "                node_data[label] = self._load_data(filename)\n",
    "            else:\n",
    "                query = f\"\"\"\n",
    "                    MATCH (n:{label})\n",
    "                    RETURN id(n) AS id, n.sbert_embedding AS embedding, n.name AS name\n",
    "                \"\"\"\n",
    "                results = self.graph.run(query).data()\n",
    "                print(label,len(results))\n",
    "                embeddings = [result['embedding'] for result in results]\n",
    "                names = [result['name'] for result in results]\n",
    "                node_data[label] = {'embeddings': embeddings, 'names': names}\n",
    "                if self.use_file_storage:\n",
    "                    self._save_data(node_data[label], filename)\n",
    "        return node_data\n",
    "\n",
    "\n",
    "    def fetch_relationships(self):\n",
    "        edge_data = {}\n",
    "        rel_types = self.graph.run(\"CALL db.relationshipTypes()\").data()\n",
    "        # This could be a class attribute\n",
    "        self.rel_type_mapping = {rel_type['relationshipType']: i for i, rel_type in enumerate(self.graph.run(\"CALL db.relationshipTypes()\").data())}\n",
    "\n",
    "\n",
    "        for rel_type in rel_types:\n",
    "            type_ = rel_type[\"relationshipType\"]\n",
    "            query = f\"\"\"\n",
    "                MATCH ()-[r:{type_}]->()\n",
    "                RETURN id(startNode(r)) AS source, id(endNode(r)) AS target, r.weight AS weight\n",
    "            \"\"\"\n",
    "            results = self.graph.run(query).data()\n",
    "            print(rel_type,len(results))\n",
    "            edge_index = torch.tensor([(result['source'], result['target']) for result in results], dtype=torch.long).t().contiguous()\n",
    "            weights = torch.tensor([result['weight'] for result in results], dtype=torch.float)\n",
    "            # Assume rel_type_mapping is defined to map relationship types to integers\n",
    "            rel_type_idx = torch.full((edge_index.size(1),), self.rel_type_mapping[type_], dtype=torch.long)\n",
    "            edge_data[type_] = {'edge_index': edge_index, 'weights': weights, 'rel_type': rel_type_idx}\n",
    "            if self.use_file_storage:\n",
    "                    self._save_data(edge_data[type_], filename)\n",
    "        return edge_data\n",
    "        \n",
    "    def to_pyg_hetero_data(self):\n",
    "        hetero_data = HeteroData()\n",
    "        \n",
    "        node_data = self.fetch_nodes()\n",
    "        for node_type, data in node_data.items():\n",
    "            hetero_data[node_type].x = data['embeddings']  # Node features\n",
    "            hetero_data[node_type].name = data['names']  # Node names as features\n",
    "            \n",
    "        edge_data = self.fetch_relationships()\n",
    "        for rel_type, data in edge_data.items():\n",
    "            hetero_data[rel_type].edge_index = data['edge_index']\n",
    "            hetero_data[rel_type].edge_attr = torch.stack([data['weights'], data['rel_type']], dim=1)  # Stack weights and relationship types\n",
    "        \n",
    "        return hetero_data\n",
    "\n",
    "def convert_database(database):\n",
    "    neo4j_store = Neo4jHeteroGraphStore(uri=host, user=user, password=password, database=database)\n",
    "    pyg_hetero_data = neo4j_store.to_pyg_hetero_data()\n",
    "    return pyg_hetero_data\n",
    "# # Access node names for a specific node type\n",
    "# print(pyg_hetero_data['Article'].name)\n",
    "\n",
    "# # Access relationship weights for a specific relationship type\n",
    "# print(pyg_hetero_data['SENT_TO'].edge_attr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9de3a1-aff3-4efa-852c-ac280f100bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyg_hetero_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".KG_env",
   "language": "python",
   "name": ".kg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
